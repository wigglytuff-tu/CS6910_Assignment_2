{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wigglytuff-tu/CS6910_Assignment_2/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "import torch\n",
        "import wandb\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms.transforms import RandomRotation"
      ],
      "metadata": {
        "id": "uTBZK4jXNzu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmWBGMMBMphl"
      },
      "outputs": [],
      "source": [
        "#Loading in pre-trained Model\n",
        "from torchvision import models\n",
        "model = models.inception_v3(pretrained = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze model weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "XpZite1qM8pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the following layer with 2 output features \n",
        "import torch.nn as nn\n",
        "\n",
        "num_ftrs = model.AuxLogits.fc.in_features\n",
        "model.AuxLogits.fc = nn.Linear(num_ftrs, 10)  #Auxillary Loss layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)          #Primary Loss layer\n",
        "model = model.to('cuda')  #Moving Model to GPU"
      ],
      "metadata": {
        "id": "fmdww0SLNT4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/CS6910/inaturalist_12K/train\"\n",
        "val_dir = \"//content/drive/MyDrive/CS6910/inaturalist_12K/val\"\n",
        "\n",
        "#Transformations\n",
        "train = transforms.Compose([\n",
        "        transforms.RandomApply(transforms =[transforms.Pad(8, padding_mode='symmetric'),\n",
        "                                        transforms.RandomAffine(degrees = 16, translate = (0.05,0.05), scale = (0.64,0.9), fill=(124,252,0))], p=0.3), \n",
        "         #Pads the image          \n",
        "         #Rotates,translates,scales,etc. images \n",
        "        transforms.RandomResizedCrop(299),  # Note that we want to use Inception v3, it requires this size of images\n",
        "                                            #Crops a random portion of image and resizes it\n",
        "        transforms.RandomHorizontalFlip(),  #Now we are not using vertical flip because we don't expect such an input in real life\n",
        "        transforms.RandomPosterize(2, p=0.2),  #posterizes the image \n",
        "\n",
        "\n",
        "        #transforms.ColorJitter(brightness=0.7, contrast=(0.1,1.5), saturation=0.4, hue=0.25),  #Jitters the given parameters\n",
        "\n",
        "        transforms.RandomGrayscale(p=0.1,),  #Randomly converts image to grayscale, note by default if input image has 3 channels,\n",
        "                                             #output image also has 3 channels\n",
        "        \n",
        "        transforms.ToTensor(),              \n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  #Default ImageNet values\n",
        "    ])\n",
        "val = transforms.Compose([           \n",
        "        transforms.Resize(299),\n",
        "        transforms.CenterCrop(299),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "#Image Datasets\n",
        "train_ds = ImageFolder(train_dir, transform = train)\n",
        "val_ds = ImageFolder(val_dir, transform = val)\n",
        "\n",
        "#Image DataLoaders\n",
        "train_dl = DataLoader(train_ds, batch_size = 8, shuffle = True, num_workers = 2, pin_memory = True)\n",
        "val_dl = DataLoader(val_ds, batch_size = 8, num_workers = 2, pin_memory = True)"
      ],
      "metadata": {
        "id": "Dh2h7gqhUyb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          scheduler,          \n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          save_file_name,\n",
        "          max_epochs_stop=3,\n",
        "          n_epochs=20,\n",
        "          print_every=2):\n",
        "  \n",
        "    wandb.init(project=\"CS6910-Assignment-2\", entity=\"purvam\", magic=True)\n",
        "  \n",
        "  # Early stopping intialization\n",
        "    epochs_no_improve = 0\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    valid_max_acc = 0\n",
        "    \n",
        "\n",
        "     # Number of epochs already trained (if using loaded in model weights)\n",
        "    try:\n",
        "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
        "    except:\n",
        "        model.epochs = 0\n",
        "        print(f'Starting Training from Scratch.\\n')\n",
        "    \n",
        "    overall_start = timer()\n",
        "    \n",
        "    # Main loop\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # keep track of training and validation loss each epoch\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        train_acc = 0\n",
        "        valid_acc = 0\n",
        "\n",
        "        # Set to training\n",
        "        scheduler.step(valid_loss)\n",
        "        model.train()\n",
        "        start = timer()\n",
        "        \n",
        "        # Training loop\n",
        "        for ii, (data, target) in enumerate(train_loader):\n",
        "            # Tensors to gpu\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Get model outputs and calculate loss\n",
        "            # Special case for inception because in training it has an auxiliary output. In train\n",
        "            # mode we calculate the loss by summing the final output and the auxiliary output\n",
        "            # but in testing we only consider the final output.\n",
        "             # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "            output, aux_output = model(data)\n",
        "\n",
        "            # Loss and backpropagation of gradients\n",
        "            loss1 = criterion(output, target)\n",
        "            loss2 = criterion(aux_output, target)\n",
        "            loss = loss1 + 0.4*loss2\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track train loss by multiplying average loss by number of examples in batch\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "            # Calculate accuracy by finding max probability\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "            # Need to convert correct tensor from int to float to average\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            # Multiply average accuracy times the number of examples in batch\n",
        "            train_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            # Track training progress\n",
        "            print(\n",
        "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
        "                end='\\r')\n",
        "\n",
        "        # After training loops ends, start validation\n",
        "        else:\n",
        "            model.epochs += 1\n",
        "\n",
        "            # Don't need to keep track of gradients\n",
        "            with torch.no_grad():\n",
        "                # Set to evaluation mode\n",
        "                model.eval()\n",
        "\n",
        "                # Validation loop\n",
        "                for data, target in valid_loader:\n",
        "                    # Tensors to gpu\n",
        "                    data, target = data.cuda(), target.cuda()\n",
        "\n",
        "                    # Forward pass\n",
        "                    output = model(data)\n",
        "\n",
        "                    # Validation loss\n",
        "                    loss = criterion(output, target)\n",
        "                    # Multiply average loss times the number of examples in batch\n",
        "                    valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "                    # Calculate validation accuracy\n",
        "                    _, pred = torch.max(output, dim=1)\n",
        "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "                    accuracy = torch.mean(\n",
        "                        correct_tensor.type(torch.FloatTensor))\n",
        "                    # Multiply average accuracy times the number of examples\n",
        "                    valid_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "                # Calculate average losses\n",
        "                train_loss = train_loss / len(train_loader.dataset)\n",
        "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "                # Calculate average accuracy\n",
        "                train_acc = train_acc / len(train_loader.dataset)\n",
        "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "\n",
        "                \n",
        "\n",
        "                # Print training and validation results\n",
        "                if (epoch + 1) % print_every == 0:\n",
        "                    print(\n",
        "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
        "                    )\n",
        "                    print(\n",
        "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
        "                    )\n",
        "\n",
        "                    wandb.log({\"Train_loss\":train_loss,\"Train_acc\":train_acc,\"val_loss\":valid_loss,\"val_Accuracy\":valid_acc})\n",
        "\n",
        "                # Save the model if validation loss decreases\n",
        "                if valid_loss < valid_loss_min:\n",
        "                    # Save model\n",
        "                    torch.save(model.state_dict(), save_file_name)\n",
        "                    # Track improvement\n",
        "                    epochs_no_improve = 0\n",
        "                    valid_loss_min = valid_loss\n",
        "                    valid_best_acc = valid_acc\n",
        "                    best_epoch = epoch\n",
        "\n",
        "                # Otherwise increment count of epochs with no improvement\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    # Trigger early stopping\n",
        "                    if epochs_no_improve >= max_epochs_stop:\n",
        "                        print(\n",
        "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "                        )\n",
        "                        total_time = timer() - overall_start\n",
        "                        print(\n",
        "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
        "                        )\n",
        "\n",
        "                        # Load the best state dict\n",
        "                        model.load_state_dict(torch.load(save_file_name))\n",
        "                        # Attach the optimizer\n",
        "                        model.optimizer = optimizer\n",
        "\n",
        "                        \n",
        "                        return model\n",
        "\n",
        "    # Attach the optimizer\n",
        "    model.optimizer = optimizer\n",
        "    # Record overall time and print out stats\n",
        "    total_time = timer() - overall_start\n",
        "    print(\n",
        "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "    )\n",
        "    print(\n",
        "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "5BcaGr3_PFGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=2)"
      ],
      "metadata": {
        "id": "aGiJ9blRPS5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    train_dl,\n",
        "    val_dl,\n",
        "    save_file_name=\"best.pth\",\n",
        "    max_epochs_stop=5,\n",
        "    n_epochs=30,\n",
        "    print_every=1)"
      ],
      "metadata": {
        "id": "HovPh2uUPW-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b20e4b2d-de74-4635-f248-32532876dfc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpurvam\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230413_113305-6oj2jdk7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/purvam/CS6910-Assignment-2/runs/6oj2jdk7' target=\"_blank\">robust-smoke-81</a></strong> to <a href='https://wandb.ai/purvam/CS6910-Assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/purvam/CS6910-Assignment-2' target=\"_blank\">https://wandb.ai/purvam/CS6910-Assignment-2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/purvam/CS6910-Assignment-2/runs/6oj2jdk7' target=\"_blank\">https://wandb.ai/purvam/CS6910-Assignment-2/runs/6oj2jdk7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:6oj2jdk7) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">robust-smoke-81</strong> at: <a href='https://wandb.ai/purvam/CS6910-Assignment-2/runs/6oj2jdk7' target=\"_blank\">https://wandb.ai/purvam/CS6910-Assignment-2/runs/6oj2jdk7</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230413_113305-6oj2jdk7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:6oj2jdk7). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230413_113306-ad61d1eh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/purvam/CS6910-Assignment-2/runs/ad61d1eh' target=\"_blank\">rich-sound-82</a></strong> to <a href='https://wandb.ai/purvam/CS6910-Assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/purvam/CS6910-Assignment-2' target=\"_blank\">https://wandb.ai/purvam/CS6910-Assignment-2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/purvam/CS6910-Assignment-2/runs/ad61d1eh' target=\"_blank\">https://wandb.ai/purvam/CS6910-Assignment-2/runs/ad61d1eh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training from Scratch.\n",
            "\n",
            "\n",
            "Epoch: 0 \tTraining Loss: 2.0366 \tValidation Loss: 0.7708\n",
            "\t\tTraining Accuracy: 51.90%\t Validation Accuracy: 76.70%\n",
            "\n",
            "Epoch: 1 \tTraining Loss: 1.8391 \tValidation Loss: 0.7392\n",
            "\t\tTraining Accuracy: 57.63%\t Validation Accuracy: 77.30%\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 1.8559 \tValidation Loss: 0.7042\n",
            "\t\tTraining Accuracy: 57.35%\t Validation Accuracy: 78.15%\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 1.7358 \tValidation Loss: 0.6697\n",
            "\t\tTraining Accuracy: 60.04%\t Validation Accuracy: 79.30%\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 1.7252 \tValidation Loss: 0.6857\n",
            "\t\tTraining Accuracy: 59.65%\t Validation Accuracy: 78.50%\n",
            "\n",
            "Epoch: 5 \tTraining Loss: 1.6889 \tValidation Loss: 0.6857\n",
            "\t\tTraining Accuracy: 60.46%\t Validation Accuracy: 78.20%\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 1.6938 \tValidation Loss: 0.6570\n",
            "\t\tTraining Accuracy: 60.41%\t Validation Accuracy: 79.90%\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 1.6764 \tValidation Loss: 0.6571\n",
            "\t\tTraining Accuracy: 60.02%\t Validation Accuracy: 78.95%\n",
            "\n",
            "Epoch: 8 \tTraining Loss: 1.6716 \tValidation Loss: 0.6625\n",
            "\t\tTraining Accuracy: 60.39%\t Validation Accuracy: 79.00%\n",
            "\n",
            "Epoch: 9 \tTraining Loss: 1.6987 \tValidation Loss: 0.6762\n",
            "\t\tTraining Accuracy: 60.30%\t Validation Accuracy: 79.45%\n",
            "\n",
            "Epoch: 10 \tTraining Loss: 1.6366 \tValidation Loss: 0.6724\n",
            "\t\tTraining Accuracy: 61.58%\t Validation Accuracy: 78.85%\n",
            "\n",
            "Epoch: 11 \tTraining Loss: 1.7021 \tValidation Loss: 0.6764\n",
            "\t\tTraining Accuracy: 60.13%\t Validation Accuracy: 78.55%\n",
            "\n",
            "Early Stopping! Total epochs: 11. Best epoch: 6 with loss: 0.66 and acc: 78.55%\n",
            "3050.07 total seconds elapsed. 254.17 seconds per epoch.\n"
          ]
        }
      ]
    }
  ]
}